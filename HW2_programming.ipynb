{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b49a9249-0832-4017-819c-6cc08b9f6435",
   "metadata": {},
   "source": [
    "Q5: Evaluation Metrics from a Multi-Class Confusion Matrix\r\n",
    "The system classified 90 animals into Cat, Dog, or Rabbit. The results are shown below:\r\n",
    "System \\ Gold\tCat\tDog\tRabbit\r\n",
    "Cat\t5\t10\\\t5\r\n",
    "Dog\t15\t20\\\t10\r\n",
    "Rabbit\t0\t1\n",
    "3.\tProgramming Implementation\r\n",
    "Write Python code that:    \r\n",
    "1.\tAccepts the confusion matrix above as input    .\r\n",
    "2.\tComputes per-class precision and recal    l.\r\n",
    "3.\tComputes macro-averaged and micro-averaged precision and reca    ll.\r\n",
    "4.\tPrints all results clearly.\r\n",
    "5\t10\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e165553-0d1e-4021-a94b-2540a2d0a8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-class metrics:\n",
      "  Cat      TP= 5  FP=15  FN=15  Precision=0.2500  Recall=0.2500\n",
      "  Dog      TP=20  FP=25  FN=25  Precision=0.4444  Recall=0.4444\n",
      "  Rabbit   TP=10  FP=15  FN=15  Precision=0.4000  Recall=0.4000\n",
      "\n",
      "Macro-averaged:\n",
      "  Precision=0.3648  Recall=0.3648\n",
      "\n",
      "Micro-averaged:\n",
      "  Precision=0.3889  Recall=0.3889\n",
      "\n",
      "Accuracy=0.3889\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Confusion matrix (rows = predicted, cols = gold)\n",
    "#            Gold:   Cat  Dog  Rabbit\n",
    "cm = np.array([[ 5,  10,   5],   # Pred Cat\n",
    "               [15,  20,  10],   # Pred Dog\n",
    "               [ 0,  15,  10]])  # Pred Rabbit\n",
    "labels = [\"Cat\", \"Dog\", \"Rabbit\"]\n",
    "# True Positives, False Positives, False Negatives\n",
    "tp = np.diag(cm)\n",
    "fp = cm.sum(axis=1) - tp\n",
    "fn = cm.sum(axis=0) - tp\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall    = tp / (tp + fn)\n",
    "\n",
    "# Macro-average\n",
    "macro_precision = precision.mean()\n",
    "macro_recall    = recall.mean()\n",
    "\n",
    "# Micro-average\n",
    "TP_total = tp.sum()\n",
    "FP_total = fp.sum()\n",
    "FN_total = fn.sum()\n",
    "micro_precision = TP_total / (TP_total + FP_total)\n",
    "micro_recall    = TP_total / (TP_total + FN_total)\n",
    "\n",
    "# print\n",
    "print(\"Per-class metrics:\")\n",
    "for i, lab in enumerate(labels):\n",
    "    print(f\"  {lab:7s}  TP={tp[i]:2d}  FP={fp[i]:2d}  FN={fn[i]:2d}  \"\n",
    "          f\"Precision={precision[i]:.4f}  Recall={recall[i]:.4f}\")\n",
    "\n",
    "print(\"\\nMacro-averaged:\")\n",
    "print(f\"  Precision={macro_precision:.4f}  Recall={macro_recall:.4f}\")\n",
    "\n",
    "print(\"\\nMicro-averaged:\")\n",
    "print(f\"  Precision={micro_precision:.4f}  Recall={micro_recall:.4f}\")\n",
    "\n",
    "# overall accuracy\n",
    "accuracy = TP_total / cm.sum()\n",
    "print(f\"\\nAccuracy={accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adf8953-21c9-4764-a4e1-71d380297d5c",
   "metadata": {},
   "source": [
    "Q8. Programming: Bigram Language Model Implementation (based on “Activity: I love NLP corpus” slide)\r\n",
    "Tasks:\r\n",
    "Write a Python program to:\r\n",
    "1.\tRead the training corpus:\r\n",
    "2.\t<s> I love NLP </s>  \r\n",
    "3.\t<s> I love deep learning </s>  \r\n",
    "4.\t<s> deep learning is fun </s>\r\n",
    "5.\tCompute unigram and bigram counts.\r\n",
    "6.\tEstimate bigram probabilities using MLE.\r\n",
    "7.\tImplement a function that calculates the probability of any given sentence.\r\n",
    "8.\tTest your function on both s    tences:\r\n",
    "o\t<s> I lov    NLP </s>\r\n",
    "o\t<s> I love deep learning </s>\r\n",
    "9.\tPrint which sentence the model prfers and why.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "253e8b3b-e527-42fb-81b2-0696353d267c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Unigram counts ===\n",
      "    </s>: 3\n",
      "     <s>: 3\n",
      "       I: 2\n",
      "     NLP: 1\n",
      "    deep: 2\n",
      "     fun: 1\n",
      "      is: 1\n",
      "learning: 2\n",
      "    love: 2\n",
      "\n",
      "=== Bigram counts & MLE probs ===\n",
      "     <s> -> I (count=2, P=0.667), deep (count=1, P=0.333)\n",
      "       I -> love (count=2, P=1.000)\n",
      "     NLP -> </s> (count=1, P=1.000)\n",
      "    deep -> learning (count=2, P=1.000)\n",
      "     fun -> </s> (count=1, P=1.000)\n",
      "      is -> fun (count=1, P=1.000)\n",
      "learning -> </s> (count=1, P=0.500), is (count=1, P=0.500)\n",
      "    love -> NLP (count=1, P=0.500), deep (count=1, P=0.500)\n",
      "\n",
      "--- S1: <s> I love NLP </s> ---\n",
      "Step probs: P(I|<s>)=0.667 × P(love|I)=1.000 × P(NLP|love)=0.500 × P(</s>|NLP)=1.000\n",
      "Total sentence probability = 0.333333\n",
      "\n",
      "--- S2: <s> I love deep learning </s> ---\n",
      "Step probs: P(I|<s>)=0.667 × P(love|I)=1.000 × P(deep|love)=0.500 × P(learning|deep)=1.000 × P(</s>|learning)=0.500\n",
      "Total sentence probability = 0.166667\n",
      "\n",
      "Preferred = S1: <s> I love NLP </s>\n",
      "Why: After 'love', the transition to 'NLP' vs 'deep' differs. The product of bigram probabilities along S1 is larger.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from math import prod\n",
    "corpus = [\n",
    "    [\"<s>\", \"I\", \"love\", \"NLP\", \"</s>\"],\n",
    "    [\"<s>\", \"I\", \"love\", \"deep\", \"learning\", \"</s>\"],\n",
    "    [\"<s>\", \"deep\", \"learning\", \"is\", \"fun\", \"</s>\"],\n",
    "]\n",
    "\n",
    "def get_unigram_bigram_counts(corpus_tokens):\n",
    "   unigrams = Counter()\n",
    "   bigrams = Counter()\n",
    "   for sent in corpus_tokens:\n",
    "        unigrams.update(sent)\n",
    "        for w1, w2 in zip(sent[:-1], sent[1:]):\n",
    "            bigrams[(w1, w2)] += 1\n",
    "   return unigrams, bigrams\n",
    "\n",
    "def bigram_mle_prob(w2, w1, bigrams, unigrams):\n",
    "    c12 = bigrams.get((w1, w2), 0)\n",
    "    c1 = unigrams.get(w1, 0)\n",
    "    return (c12 / c1) if c1 > 0 else 0.0\n",
    "\n",
    "def sentence_prob(sent_tokens, bigrams, unigrams):\n",
    "    probs = [bigram_mle_prob(w2, w1, bigrams, unigrams) for w1, w2 in zip(sent_tokens[:-1], sent_tokens[1:])]\n",
    "    return prod(probs), list(zip(sent_tokens[:-1], sent_tokens[1:], probs))\n",
    "\n",
    "def build_table(bigrams, unigrams):\n",
    "    table = defaultdict(list)\n",
    "    for (w1, w2), c in sorted(bigrams.items()):\n",
    "        p = bigram_mle_prob(w2, w1, bigrams, unigrams)\n",
    "        table[w1].append((w2, c, p))\n",
    "    return table\n",
    "\n",
    "def main():\n",
    "    unigrams, bigrams = get_unigram_bigram_counts(corpus)\n",
    "    table = build_table(bigrams, unigrams)\n",
    "    def bigram_line(w1, entries):\n",
    "        return f\"{w1:>8} -> \" + \", \".join([f\"{w2} (count={c}, P={p:.3f})\" for w2, c, p in entries])\n",
    "\n",
    "    print(\"=== Unigram counts ===\")\n",
    "    for w, c in sorted(unigrams.items()):\n",
    "        print(f\"{w:>8}: {c}\")\n",
    "    print(\"\\n=== Bigram counts & MLE probs ===\")\n",
    "    for w1 in sorted(table.keys()):\n",
    "        print(bigram_line(w1, table[w1]))\n",
    "\n",
    "    s1 = [\"<s>\", \"I\", \"love\", \"NLP\", \"</s>\"]\n",
    "    s2 = [\"<s>\", \"I\", \"love\", \"deep\", \"learning\", \"</s>\"]\n",
    "    label_map = {\"S1: <s> I love NLP </s>\": s1, \"S2: <s> I love deep learning </s>\": s2}\n",
    "\n",
    "    results = {}\n",
    "    for label, sent in label_map.items():\n",
    "        p, steps = sentence_prob(sent, bigrams, unigrams)\n",
    "        results[label] = {\"prob\": p, \"steps\": steps}\n",
    "\n",
    "    for label, info in results.items():\n",
    "        step_str = \" × \".join([f\"P({w2}|{w1})={p:.3f}\" for w1, w2, p in info[\"steps\"]])\n",
    "        print(f\"\\n--- {label} ---\")\n",
    "        print(\"Step probs:\", step_str)\n",
    "        print(f\"Total sentence probability = {info['prob']:.6f}\")\n",
    "\n",
    "    best_label = max(results.items(), key=lambda kv: kv[1][\"prob\"])[0]\n",
    "    print(f\"\\nPreferred = {best_label}\")\n",
    "    if best_label.startswith(\"S1\"):\n",
    "        print(\"Why: After 'love', the transition to 'NLP' vs 'deep' differs. \"\n",
    "              \"The product of bigram probabilities along S1 is larger.\")\n",
    "    else:\n",
    "        print(\"Why: After 'love', the transition to 'deep' (and onward) yields a higher product.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f7476c-767d-4ad6-b01e-93b623a202aa",
   "metadata": {},
   "source": [
    "Which sentence wins & why\n",
    "S1 is preferred because both sentences share the same early transitions (<s>→I, I→love) and then diverge at “love”. After that point, S2 has to take one extra hop (learning → </s> with probability 0.5). That extra 0.5 factor makes S2’s total probability half of S1’s.\n",
    "(This exercise fits the “Naive Bayes ↔ language modeling” section from your slides—estimating probabilities from counts via MLE and multiplying along the path.) \n",
    "If you want, I can also add Laplace smoothing or perplexity reporting on top of this.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
